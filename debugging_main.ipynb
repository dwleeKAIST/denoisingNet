{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time \n",
    "from os import path, makedirs\n",
    "\n",
    "from BSD500_gray import imgSet_wv\n",
    "from nets import denoising_net as model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db    = imgSet_wv(l_dir_train='./data/train_gray/', l_dir_test='./data/test_gray/', \\\n",
    "                  noise_stdev=15, wv_type='haar')\n",
    "totalN = db.getTotalN()   \n",
    "\n",
    "BATCH_SIZE = 32\n",
    "patchSize  = [20, 20]\n",
    "NUM_EPOCHS = 1000\n",
    "\n",
    "IMG_SIZE_Y, IMG_SIZE_X, IMG_SIZE_CH = db.getDimForNet()\n",
    "#print(db.getDimForNet())\n",
    "\n",
    "train_size = db.getTrainN()\n",
    "test_size  = db.getTestN()\n",
    "dtype      = tf.float32\n",
    "\n",
    "##\n",
    "ckpt_dir  = './result/wave15sgm_patch_BSD_gray/ckpt_dir'\n",
    "log_dir   = './result/wave15sgm_patch_BSD_gray/log_dir'\n",
    "\n",
    "if not path.exists(log_dir):\n",
    "    makedirs(log_dir)\n",
    "if not path.exists(ckpt_dir):\n",
    "    makedirs(ckpt_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "580 241 161 4\n",
      "500 80\n"
     ]
    }
   ],
   "source": [
    "print(totalN,IMG_SIZE_X,IMG_SIZE_Y,IMG_SIZE_CH)\n",
    "print(train_size,test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## data feed dict and network \n",
    "data_node   = tf.placeholder( dtype, shape = (None, None, None, IMG_SIZE_CH) )\n",
    "label_node  = tf.placeholder( dtype, shape = (None, None, None, IMG_SIZE_CH) )\n",
    "\n",
    "net_out       = model.net(data_node, residual_tag=1, IMG_SIZE_CH=4)\n",
    "\n",
    "loss          = tf.reduce_mean(tf.squared_difference(net_out,label_node,\"L2_loss\"))\n",
    "tf.summary.scalar(\"loss\", loss)\n",
    "\n",
    "PIXEL_MAX     = 255.0\n",
    "_20_div_Log10 = 8.6859\n",
    "psnr          = tf.log(PIXEL_MAX/tf.sqrt(loss))*_20_div_Log10\n",
    "tf.summary.scalar(\"PSNR\", psnr)\n",
    "\n",
    "batch         = tf.Variable(0, dtype=dtype)\n",
    "#lr            = tf.train.exponential_decay(0.01, batch*BATCH_SIZE, totalN, 0.95, staircase=True )\n",
    "lr            = tf.train.exponential_decay(0.1, batch*BATCH_SIZE, totalN, 0.95, staircase=False )\n",
    "\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr, beta1=0.5, beta2=0.9).minimize(loss, colocate_gradients_with_ops=True)\n",
    "#optimizer = tf.train.RMSPropOptimizer(learning_rate=lr, beta1=0.5, beta2=0.9).minimize(loss,                                        var_list=lib.params_with_name('cost'), colocate_gradients_with_ops=True)\n",
    "merged_all    = tf.summary.merge_all()\n",
    "saver         = tf.train.Saver()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def myNumExtractor(s):\n",
    "    head = s.rstrip('0123456789')\n",
    "    tail = s[len(head):]\n",
    "    return int(tail)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    len_batch      = int(train_size/BATCH_SIZE)\n",
    "    len_batch_test = int(test_size/BATCH_SIZE)\n",
    "    \n",
    "    # check whether it have beed trained or not\n",
    "    latest_ckpt = tf.train.latest_checkpoint(ckpt_dir)\n",
    "    if latest_ckpt==None:\n",
    "        print(\"START! initially!\")\n",
    "        tf.global_variables_initializer().run()\n",
    "        epoch_start=0\n",
    "    else:\n",
    "        print(\"STARTING from saved model-\"+latest_ckpt)\n",
    "        saver.restore(sess,latest_ckpt)\n",
    "        epoch_start = myNumExtractor(latest_ckpt)+1\n",
    "    \n",
    "    summary_writer = tf.summary.FileWriter(log_dir, sess.graph)\n",
    "        \n",
    "    for iEpoch in range(epoch_start, NUM_EPOCHS) :\n",
    "        start_time  = time.time()\n",
    "        #Loop over all batches\n",
    "        \n",
    "        db.shuffleTrain_id()\n",
    "        loss_train = 0.0\n",
    "        \n",
    "        for iBatch in range(len_batch):\n",
    "            \n",
    "            offset       = (iBatch*BATCH_SIZE)\n",
    "            #ipdb.set_trace()\n",
    "            batch_data, batch_labels = db.getPWBatch(isTrain=1, batchStart=offset, batchEnd=offset+BATCH_SIZE, patchSize=patchSize, Aug=1)\n",
    "            \n",
    "            _, merged, l_train = sess.run([optimizer, merged_all, loss],feed_dict = {data_node : batch_data, label_node : batch_labels})\n",
    "            if (iBatch%20==0):\n",
    "                print(\"---- processing...EPOCH#%d %d-th (%d-%d): LOSS %.4f\" % (iEpoch, iBatch, offset, offset+BATCH_SIZE, l_train))\n",
    "            loss_train += l_train\n",
    "            summary_writer.add_summary(merged, iEpoch*len_batch+iBatch)\n",
    "            \n",
    "            #end of for loop - for training\n",
    "        \n",
    "        print(\"---1 epoch of train DONE -- time : %.2f min\" % (float(time.time()-start_time)/60.0) )\n",
    "        print(\"EPOCH(%d - train)--Loss : %.4f\" % (iEpoch, loss_train/len_batch))\n",
    "            \n",
    "        \n",
    "        loss_test = 0.0\n",
    "        psnr_test = 0.0\n",
    "        for iBatch_test in range(len_batch_test):\n",
    "            offset       = iBatch_test*BATCH_SIZE\n",
    "            batch_data, batch_labels = db.getPWBatch(isTrain=0, batchStart=offset, batchEnd=offset+BATCH_SIZE, patchSize=patchSize, Aug=0)\n",
    "            \n",
    "            l_test, prediction_test, p_test = sess.run([loss, net_out,psnr],feed_dict={data_node : batch_data, label_node : batch_labels})\n",
    "            loss_test += l_test\n",
    "            psnr_test += p_test\n",
    "        \n",
    "        print(\"EPOCH(%d - test )--Loss : %.4f , PSNR : %.4f\" % (iEpoch, loss_test/len_batch_test, psnr_test/len_batch_test))\n",
    "        print(\"-TOTAL time for 1 epoch : %.2f min\" % (float(time.time()-start_time)/60.0) )\n",
    "\n",
    "        path_saved = saver.save(sess, path.join(ckpt_dir, \"model.ckpt\"), global_step=iEpoch)\n",
    "        print(\"The model saved in file :\"+path_saved)\n",
    "        \n",
    "        ## saving jpg\n",
    "        batch_data, batch_labels = db.getABatch(isTrain=0, batchStart=7)\n",
    "        prediction_test = sess.run(net_out, feed_dict={data_node : batch_data, label_node : batch_labels})\n",
    "        db.np2img_save(batch_data, prediction_test, batch_labels, log_dir, save_str='test1')\n",
    "        \n",
    "        batch_data, batch_labels = db.getABatch(isTrain=0, batchStart=8)\n",
    "        prediction_test = sess.run(net_out, feed_dict={data_node : batch_data, label_node : batch_labels})\n",
    "        db.np2img_save(batch_data, prediction_test, batch_labels, log_dir, save_str='test2')\n",
    "        \n",
    "        batch_data, batch_labels = db.getABatch(isTrain=0, batchStart=9)\n",
    "        prediction_test = sess.run(net_out, feed_dict={data_node : batch_data, label_node : batch_labels})\n",
    "        db.np2img_save(batch_data, prediction_test, batch_labels, log_dir, save_str='test3')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
